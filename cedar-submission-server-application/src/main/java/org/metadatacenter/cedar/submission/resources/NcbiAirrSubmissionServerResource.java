package org.metadatacenter.cedar.submission.resources;

import com.codahale.metrics.annotation.Timed;
import org.apache.commons.fileupload.FileItem;
import org.apache.commons.fileupload.FileUploadException;
import org.apache.commons.fileupload.disk.DiskFileItemFactory;
import org.apache.commons.fileupload.servlet.ServletFileUpload;
import org.joda.time.DateTimeZone;
import org.metadatacenter.cedar.submission.util.fileupload.flow.FlowChunkData;
import org.metadatacenter.cedar.submission.util.fileupload.flow.FlowChunkUploadManager;
import org.metadatacenter.cedar.submission.util.fileupload.flow.FlowUploadUtil;
import org.metadatacenter.cedar.util.dw.CedarMicroserviceResource;
import org.metadatacenter.config.CedarConfig;
import org.metadatacenter.exception.CedarException;
import org.metadatacenter.rest.context.CedarRequestContext;
import org.metadatacenter.rest.context.CedarRequestContextFactory;
import org.metadatacenter.submission.AIRRTemplate2SRAConverter;
import org.metadatacenter.submission.BioSampleValidator;
import org.metadatacenter.submission.biosample.AIRRTemplate;
import org.metadatacenter.submission.ncbiairr.NcbiAirrSubmission;
import org.metadatacenter.submission.ncbiairr.queue.NcbiAirrSubmissionQueueService;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.management.InstanceNotFoundException;
import javax.ws.rs.Consumes;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;
import javax.xml.bind.JAXBException;
import javax.xml.datatype.DatatypeConfigurationException;
import java.io.*;
import java.util.ArrayList;
import java.util.List;
import java.util.UUID;

import static org.metadatacenter.rest.assertion.GenericAssertions.LoggedIn;

/**
 * See here for submission instructions to NCBI:
 * <p>
 * https://docs.google.com/document/d/1tmPinCgaTwBkTsOwjitquFc0ZUN65w5xZs30q5phRkY/edit
 */
@Path("/command")
@Produces(MediaType.APPLICATION_JSON)
public class NcbiAirrSubmissionServerResource extends CedarMicroserviceResource {

  final static Logger logger = LoggerFactory.getLogger(NcbiAirrSubmissionServerResource.class);

  private final BioSampleValidator bioSampleValidator;

  private final AIRRTemplate2SRAConverter airrTemplate2SRAConverter;

  private static NcbiAirrSubmissionQueueService ncbiAirrSubmissionQueueService;

  public NcbiAirrSubmissionServerResource(CedarConfig cedarConfig) {
    super(cedarConfig);
    this.bioSampleValidator = new BioSampleValidator();
    this.airrTemplate2SRAConverter = new AIRRTemplate2SRAConverter();
  }

  public static void injectServices(NcbiAirrSubmissionQueueService ncbiAirrSubmissionQueueService) {
    NcbiAirrSubmissionServerResource.ncbiAirrSubmissionQueueService = ncbiAirrSubmissionQueueService;
  }

  /**
   * The {@link AIRRTemplate} class is generated by jsonschema2pojo from the
   * AIRRTemplate.json JSON Schema file in the resources directory. This file
   * contains the CEDAR template that defines the example SRA submission generated from an AIRR template.
   * An SRA submission incorporates BioSample metadata and a BioProject data.
   *
   * @param airrInstance An instance of an AIRR template
   * @return A validation response
   */
  @POST
  @Timed
  @Path("/validate-airr")
  @Consumes(MediaType.APPLICATION_JSON)
  public Response validate(
      AIRRTemplate airrInstance) throws CedarException {

    CedarRequestContext c = CedarRequestContextFactory.fromRequest(request);
    c.must(c.user()).be(LoggedIn);

    try {
      String bioSampleSubmissionXML = this.airrTemplate2SRAConverter
          .generateSRASubmissionXMLFromAIRRTemplateInstance(airrInstance);

      return Response.ok(this.bioSampleValidator.validateBioSampleSubmission(bioSampleSubmissionXML)).build();
    } catch (JAXBException | DatatypeConfigurationException e) {
      return Response.status(Response.Status.INTERNAL_SERVER_ERROR).build();
    }
  }

  /**
   * This endpoint receives multiple chunks of a file and assemblies them. When the upload is complete, it triggers
   * the FTP upload to the NCBI.
   * It is based on some ideas from: https://github.com/flowjs/flow
   * .js/blob/master/samples/java/src/resumable/js/upload/UploadServlet.java
   * TODO: deal with multi-file submissions
   */
  @POST
  @Timed
  @Path("/upload-airr-to-cedar")
  @Consumes(MediaType.MULTIPART_FORM_DATA)
  public Response uploadAIRRToCEDAR() throws CedarException {

    CedarRequestContext c = CedarRequestContextFactory.fromRequest(request);
    c.must(c.user()).be(LoggedIn);

    // Check that this is a file upload request
    if (ServletFileUpload.isMultipartContent(request)) {
      try {

        List<FileItem> fileItems = new ServletFileUpload(new DiskFileItemFactory()).parseRequest(request);
        FlowChunkData info = FlowUploadUtil.getFlowChunkData(fileItems);

        // Create uploaded file
        String cedarUserId = FlowUploadUtil.getLastFragmentOfUrl(c.getCedarUser().getId());
        File tempDir = new File(FlowUploadUtil.getTempFolderName("ncbi-upload", cedarUserId, info.flowIdentifier));
        tempDir.mkdirs();
        File uploadedFile = new File(tempDir + "/" + info.flowFilename);
        uploadedFile.createNewFile();
        logger.info("File created. Path: " + uploadedFile);

        RandomAccessFile raf = new RandomAccessFile(uploadedFile, "rw");

        // Seek to position
        raf.seek((info.flowChunkNumber - 1) * info.flowChunkSize);
        // Save to file
        InputStream is = info.getFlowFileInputStream();
        long read = 0;
        long content_length = request.getContentLength();
        byte[] bytes = new byte[1024 * 100];
        while (read < content_length) {
          int r = is.read(bytes);
          if (r < 0) {
            break;
          }
          raf.write(bytes, 0, r);
          read += r;
        }
        raf.close();

        // Update the map
        FlowChunkUploadManager.getInstance().increaseUploadedChunksCount(info.getFlowIdentifier(), info
            .getFlowTotalChunks());

        // Check if the upload is complete and trigger the FTP submission to NCBI
        if (FlowChunkUploadManager.getInstance().isUploadFinished(info.getFlowIdentifier())) {
          FlowChunkUploadManager.getInstance().removeFlowStatus(info.getFlowIdentifier());
          logger.info("Upload completed. File: " + info.getFlowFilename());
          String submissionDir = FlowUploadUtil.getDateBasedFolderName(DateTimeZone.UTC) + "_test";
          logger.info("Starting submission to the NCBI. Destination folder: " + submissionDir);

          // Enqueue submission
          logger.info("Enqueuing submission");
          String submissionId = UUID.randomUUID().toString();
          List<String> localFilePaths = new ArrayList<>();
          localFilePaths.add(uploadedFile.getAbsolutePath());
          NcbiAirrSubmission submission = new NcbiAirrSubmission(submissionId, cedarUserId, localFilePaths, submissionDir);
          ncbiAirrSubmissionQueueService.enqueueSubmission(submission);
        }
      } catch (FileNotFoundException e) {
        e.printStackTrace();
      } catch (IOException e) {
        e.printStackTrace();
      } catch (InstanceNotFoundException e) {
        e.printStackTrace();
      } catch (FileUploadException e) {
        e.printStackTrace();
      }

      return Response.ok().build();
    } else {
      return Response.status(Response.Status.BAD_REQUEST).build();
    }
  }

  /**
   * This endpoint triggers the submission to the NCBI of files previously uploaded to CEDAR using the "/upload-airr-to-cedar" endpoint
   */
//  @POST
//  @Timed
//  @Path("/submit-to-ncbi")
//  @Consumes(MediaType.APPLICATION_JSON)
//  public Response submit() throws CedarException {
//
//    logger.info("*** Submitting to NCBI...");
//
//    CedarRequestContext c = CedarRequestContextFactory.fromRequest(request);
//    c.must(c.user()).be(LoggedIn);
//
//    JsonNode submissionJson = c.request().getRequestBody().asJson();
//    ObjectMapper mapper = new ObjectMapper();
//    try {
//      NcbiAirrSubmission submission = mapper.treeToValue(submissionJson, NcbiAirrSubmission.class);
//      List<File> filesToSubmit = new ArrayList<>();
//      for (String filePath : submission.getLocalFilePaths()) {
//        filesToSubmit.add(new File(filePath));
//      }
//      logger.info("Uploading to NCBI... (simulation)");
//      Thread.sleep(60000);
//      logger.info("Submission successful!!!! (simulation). Submission id: " + submission.getId() + "; No. files: " + submission.getLocalFilePaths().size());
//      UploadService.uploadToNcbi(submission.getSubmissionFolder(), filesToSubmit, cedarConfig.getSubmissionConfig().getNcbi().getSra().getFtp());
//    } catch (JsonProcessingException e) {
//      return Response.status(Response.Status.BAD_REQUEST).build();
//    }
//    catch (Exception e) {
//      // TODO: improve error messages
//      return Response.status(Response.Status.INTERNAL_SERVER_ERROR).build();
//    }
//    return Response.ok().build();
//  }



}


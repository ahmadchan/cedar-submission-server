package org.metadatacenter.cedar.submission.resources;

import com.codahale.metrics.annotation.Timed;
import com.google.common.base.Stopwatch;
import com.google.common.io.Files;
import org.apache.commons.fileupload.FileItem;
import org.apache.commons.fileupload.FileUploadException;
import org.apache.commons.fileupload.disk.DiskFileItemFactory;
import org.apache.commons.fileupload.servlet.ServletFileUpload;
import org.joda.time.DateTime;
import org.joda.time.DateTimeZone;
import org.metadatacenter.cedar.submission.resources.uploader.FileUploader;
import org.metadatacenter.cedar.submission.resources.uploader.FtpUploader;
import org.metadatacenter.cedar.submission.resources.uploader.UploaderCreationException;
import org.metadatacenter.cedar.submission.util.fileupload.flow.FlowChunkData;
import org.metadatacenter.cedar.submission.util.fileupload.flow.FlowChunkUploadManager;
import org.metadatacenter.cedar.submission.util.fileupload.flow.FlowUploadUtil;
import org.metadatacenter.cedar.util.dw.CedarMicroserviceResource;
import org.metadatacenter.config.CedarConfig;
import org.metadatacenter.config.FTPConfig;
import org.metadatacenter.exception.CedarException;
import org.metadatacenter.rest.context.CedarRequestContext;
import org.metadatacenter.rest.context.CedarRequestContextFactory;
import org.metadatacenter.submission.AIRRTemplate2SRAConverter;
import org.metadatacenter.submission.BioSampleValidator;
import org.metadatacenter.submission.biosample.AIRRTemplate;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.management.InstanceNotFoundException;
import javax.ws.rs.Consumes;
import javax.ws.rs.POST;
import javax.ws.rs.Path;
import javax.ws.rs.Produces;
import javax.ws.rs.core.MediaType;
import javax.ws.rs.core.Response;
import javax.xml.bind.JAXBException;
import javax.xml.datatype.DatatypeConfigurationException;
import java.io.*;
import java.util.ArrayList;
import java.util.Collection;
import java.util.List;
import java.util.Optional;
import java.util.concurrent.TimeUnit;

import static org.metadatacenter.rest.assertion.GenericAssertions.LoggedIn;

/**
 * See here for submission instructions to NCBI:
 * <p>
 * https://docs.google.com/document/d/1tmPinCgaTwBkTsOwjitquFc0ZUN65w5xZs30q5phRkY/edit
 */
@Path("/command")
@Produces(MediaType.APPLICATION_JSON)
public class AIRRSubmissionServerResource
    extends CedarMicroserviceResource {
  final static Logger logger = LoggerFactory.getLogger(AIRRSubmissionServerResource.class);

  private final BioSampleValidator bioSampleValidator;

  private final AIRRTemplate2SRAConverter airrTemplate2SRAConverter;

  public AIRRSubmissionServerResource(CedarConfig cedarConfig) {
    super(cedarConfig);
    this.bioSampleValidator = new BioSampleValidator();
    this.airrTemplate2SRAConverter = new AIRRTemplate2SRAConverter();
  }

  /**
   * The {@link AIRRTemplate} class is generated by jsonschema2pojo from the
   * AIRRTemplate.json JSON Schema file in the resources directory. This file
   * contains the CEDAR template that defines the example SRA submission generated from an AIRR template.
   * An SRA submission incorporates BioSample metadata and a BioProject data.
   *
   * @param airrInstance An instance of an AIRR template
   * @return A validation response
   */
  @POST
  @Timed
  @Path("/validate-airr")
  @Consumes(MediaType.APPLICATION_JSON)
  public Response validate(
      AIRRTemplate airrInstance) throws CedarException {

    CedarRequestContext c = CedarRequestContextFactory.fromRequest(request);
    c.must(c.user()).be(LoggedIn);

    try {
      String bioSampleSubmissionXML = this.airrTemplate2SRAConverter
          .generateSRASubmissionXMLFromAIRRTemplateInstance(airrInstance);

      return Response.ok(this.bioSampleValidator.validateBioSampleSubmission(bioSampleSubmissionXML)).build();
    } catch (JAXBException | DatatypeConfigurationException e) {
      return Response.status(Response.Status.INTERNAL_SERVER_ERROR).build();
    }
  }


  /**
   * Upload a list of files to the NCBI server via the FTP protocol. For the NCBI submission, the files
   * should include submission.xml and FASTQ files. All these files will be stored in a remote directory
   * provided by the input parameter 'submissionDir'.
   *
   * @param submissionDir The directory name to be created at the remote server to store all the files.
   * @param listOfFiles   A list of files to be uploaded
   * @throws IOException               When upload failed due to I/O difficulties.
   * @throws UploaderCreationException When the FTP uploader failed to be created (e.g., hostname not found or
   * invalid credential)
   */
  private void upload(String submissionDir, Collection<File> listOfFiles) throws IOException,
      UploaderCreationException {
    FTPConfig ftpConfig = cedarConfig.getSubmissionConfig().getNcbi().getSra().getFtp();
    FileUploader uploader = null;
    try {
      uploader = FtpUploader.createNewUploader(
          ftpConfig.getHost(),
          ftpConfig.getUser(),
          ftpConfig.getPassword(),
          Optional.of(ftpConfig.getSubmissionDirectory()));
      uploadResourceFiles(uploader, submissionDir, listOfFiles);
//      uploadSubmitReadyFile(uploader, submissionDir);

    } finally {
      if (uploader != null) {
        try {
          uploader.disconnect();
        } catch (IOException e) {
          String message = String.format("Error while disconnecting from %s", ftpConfig.getHost());
          logger.error(message + ": " + e.getMessage());
        }
      }
    }
  }

  private void uploadResourceFiles(FileUploader uploader, String submissionDir, Collection<File> listOfFiles) throws
      IOException {
    for (File file : listOfFiles) {
      Stopwatch stopwatch = Stopwatch.createStarted();
      logger.info("Submission in progress: Uploading '{}' file...", file.getName());
      uploader.store(submissionDir, file);
      logger.info("... uploaded in {} s", stopwatch.elapsed(TimeUnit.SECONDS));
    }
  }

  private void uploadSubmitReadyFile(FileUploader uploader, String submissionDir) throws IOException {
    logger.info("Submission in progress: Uploading 'submit.ready' file...");
    File submitReady = createSubmitReadyFile();
    try {
      uploader.store(submissionDir, submitReady);
    } finally {
      if (submitReady != null) {
        submitReady.delete(); // remove traces
      }
    }
  }

  private static File createSubmitReadyFile() throws IOException {
    File submitReady = new File("submit.ready");
    Files.touch(submitReady);
    return submitReady;
  }

  /**
   * This endpoint receives multiple chunks of a file and assemblies them. When the upload is complete, it triggers
   * the FTP upload to the NCBI.
   * It is based on some ideas from: https://github.com/flowjs/flow
   * .js/blob/master/samples/java/src/resumable/js/upload/UploadServlet.java
   * TODO: deal with multi-file submissions
   */
  @POST
  @Timed
  @Path("/upload-airr-to-cedar")
  @Consumes(MediaType.MULTIPART_FORM_DATA)
  public Response uploadAIRRToCEDAR() throws CedarException {

    CedarRequestContext c = CedarRequestContextFactory.fromRequest(request);
    c.must(c.user()).be(LoggedIn);

    // Check that this is a file upload request
    if (ServletFileUpload.isMultipartContent(request)) {
      try {
        List<FileItem> fileItems = new ServletFileUpload(new DiskFileItemFactory()).parseRequest(request);
        FlowChunkData info = FlowUploadUtil.getFlowChunkData(fileItems);
        RandomAccessFile raf = null;
        try {
          File uploadedFile = File.createTempFile(FlowUploadUtil.getFileNamePrefix(info.flowFilename),
              FlowUploadUtil.getFileNameSuffix(info.flowFilename));

          // The file will be deleted when the virtual machine terminates. We will also call uploadedFile.delete() when
          // the upload to the NCBI is complete. If for some reason the upload fails, the file will be deleted when
          // the VM terminates.
          uploadedFile.deleteOnExit();

          raf = new RandomAccessFile(uploadedFile, "rw");

          // Seek to position
          raf.seek((info.flowChunkNumber - 1) * info.flowChunkSize);
          // Save to file
          InputStream is = info.getFlowFileInputStream();
          long read = 0;
          long content_length = request.getContentLength();
          byte[] bytes = new byte[1024 * 100];
          while (read < content_length) {
            int r = is.read(bytes);
            if (r < 0) {
              break;
            }
            raf.write(bytes, 0, r);
            read += r;
          }
          raf.close();

          // Update the map
          FlowChunkUploadManager.getInstance().increaseUploadedChunksCount(info.getFlowIdentifier(), info
              .getFlowTotalChunks());

          // Check if the upload is complete and trigger the FTP submission to NCBI
          if (FlowChunkUploadManager.getInstance().isUploadFinished(info.getFlowIdentifier())) {
            FlowChunkUploadManager.getInstance().removeFlowStatus(info.getFlowIdentifier());
            logger.info("Upload completed. File: " + info.getFlowFilename());
            String submissionDir = DateTime.now(DateTimeZone.UTC).toString().replace( ":" , "-" ) + "-test";
            logger.info("Starting submission to the NCBI. Destination folder: " + submissionDir);
            List<File> filesForNCBI = new ArrayList<>();
            filesForNCBI.add(uploadedFile);
            upload(submissionDir,filesForNCBI);
          }
        } catch (FileNotFoundException e) {
          e.printStackTrace();
        } catch (IOException e) {
          e.printStackTrace();
        } catch (InstanceNotFoundException e) {
          e.printStackTrace();
        } catch (UploaderCreationException e) {
          e.printStackTrace();
        }
      } catch (FileUploadException e) {
        e.printStackTrace();
      }
      return Response.ok().build();
    } else {
      return Response.status(Response.Status.BAD_REQUEST).build();
    }
  }

}

